CPU，内存，I/O速度不一致，导致运行效率问题，多线程并发执行可以提高效率，带来了并发问题；

# 可见性
线程A修改共享变量后，线程B能够立刻看见，称为可见性；
CPU和内存之间存在CPU缓存，多核CPU，每个线程在不同的核上，操作不同的缓存，内存中的一个变量，会在不同的核上，有不同的副本，导致并发问题；在Java中，每个线程有自己工作内存，用于保存主内存中的副本，不同副本之间的共享变量同步问题，这和CPU缓存是同一个问题；

***JVM内存模型和主内存，CPU寄存器，CPU缓存的对应性？***

# 原子性
一个或多个操作在CPU执行过程中，不会被中断，称为CPU的原子性；而在我们的实践开发中，面对高级语言编程，某个操作实际是由多个CPU指令组成，不具备CPU的原子性，使得在线程切换时，导致的并发问题；

# 有序性
编译器为了优化性能，会在不修改逻辑的情况下，改变代码执行顺序；

***双重检查锁创建单例产生的空指针问题？***

```
public class Singleton {

  static Singleton instance;

  static Singleton getInstance(){

    if (instance == null) {

      synchronized(Singleton.class) {

        if (instance == null)

          instance = new Singleton();

        }

    }

    return instance;

  }

}
```
一般理解的创建对象操作是：分配内存->初始化对象->对象地址赋值，new操作被优化后，实际步骤是：分配内存->对象地址赋值->初始化对象，所以在多线程，在对象地址赋值后，但并未初始化对象之前，拿到了非空对象，但访问其成员变量出现异常。如果给instance加上volatile关键字，禁止指令重排。

***缓存，线程，编译优化的目的是提高代码执行效率，但缓存带来的可见性问题，线程切换带来的原子性问题，编译优化带来的有序性问题会导致并发问题；***
***那么也就是说，通过禁用缓存，禁止编译优化，能够解决并发带来的可见性和有序性问题，更进一步则是，如何灵活的按需禁用***


# Java内存模型
Java内存模型规范了JVM提供按需禁用缓存和编译优化的方法；包括volatile，final，synchronized三个关键字，以及六项Happen-Before规则；

## volatile
volatile的中文意思易变的，不稳定的；该关键字能实现比synchronized更弱的同步机制，能够解决可见性和有序性的问题：
- 可见性：volatile保证了线程修改了值后，会立即同步到主内存，每次获取值时，都会从主内存刷新，相当于跳过了缓存的作用；
- 有序性：volatile保证了，会在变量赋值操作后，加入内存屏障的指令（使得内存屏障后的代码不能移动到它前面），这样该变量不会受到重排序的影响；

## Happens-Before六原则
Happens-Before原则针对JVM代码编译优化，指令重排的问题，定义了一些禁止编译优化的场景，保证并发编程的正确性；Happens-Before表示前面一个操作的结构对后续操作是可见的（可获取的）。

1. 程序的顺序性规则
   在一个线程中，按照程序顺序，前面的操作对后续任意操作可见；
2. volatile变量规则
   对一个volatile变量的写操作，对后续这个变量的读操作可见；
3. 传递性规则
   a happens-before b，b happens-before c，那么a happens-before c；
4. 管程中的锁规则
   一个锁的解锁，对于后续的该锁的加锁操作可见；
5. 线程start规则
   线程A启动线程B，线程A启动线程B之前的操作对于线程B是可见的；
6. 线程join规则
   线程A中，B.join使得A等待B线程执行完成，完成后，线程B的操作对于线程A是可见的；

## synchronized

## final不变性
- 写final域的重排规则
 禁止对final域的写操作重排到构造函数外；保证了，对象被其它线程可见之前，已经被正确的初始化；另外不能再构造函数中将final对象指向外部引用，造成“逃逸”；
 
- 读final域的重排规则
 在一个线程中，初次读该对象引用与初次读该对象final域，JVM会禁止重排；

# 互斥锁
线程切换导致了原子性问题，如果能够保证共享变量修改的互斥性，即同一时刻只有一个线程执行；**解决原子性问题，就是保证中间状态对外不可见；**
临界区：表示一段需要互斥执行的代码；
锁和受保护资源是1：N的关系，一把锁可以保护多个资源，但多把锁不能保护一个资源；

## synchronized
 - 对象锁：某个实例化对象作为被保护资源
       --- 方法锁：成员方法添加synchronized关键字，默认对this对象加锁，该方法成为临界区；
       --- 同步代码块：方法中的代码块，对某个对象加锁，该代码块成为临界区；	
 - 类锁：某个类的Class对象作为被保护资源
       --- 方法锁：静态方法添加synchronized关键字，默认对该类的Class对象加锁，该方法成为临界区；
       --- 同步代码块：方法中的代码块，对某个类的Class对象加锁，该代码块成为临界区；

***如何使用锁保护多个资源***
- 对于受保护的多个资源，如果他们之间没有必然联系，每个资源使用单独的锁，这种精细化的操作，能够提升并发效率，这种锁也叫作细粒度锁；
- 对于受保护的多个资源，如果他们之间有关联，使用能覆盖所有资源的锁，比如类锁，这些资源会共享该锁；

# 死锁
对多个受保护的资源，使用单独的锁进行保护，如果这些资源之间存在相互依赖（竞争），导致死锁的产生；
死锁：一组互相竞争资源的线程相互等待，导致“永久”阻塞的现象；

## 预防死锁
死锁发生的四个必要条件：
1. 互斥，共享资源A只能被某一个线程占用，不能同时被多个线程占有；
2. 占有且等待，线程T1已经取得共享资源A，在等待共享资源B，不释放共享资源A；
3. 不可抢占，其它线程不能强行抢占线程T1占有的资源；
4. 循环等待：线程T1等待线程T2所占有的共享资源B，线程T2等待线程T1所占有的共享资源A；

因此，只要破坏这四个必要条件中的任意一个，则必然不会发生死锁，对于条件1，我们使用锁就是为了产生互斥，所有不考虑，所以需要破坏条件2,3,4来解决死锁：
- 占有且等待，让线程获取所有的共享资源，不再等待；
- 不可抢占，线程主动释放占有的共享资源；Java的Lock类
- 循环等待，打破循环，按照某种规则，依次获取共享资源；

# 等待-通知 | 生产者-消费者
使用循环等待的方式，可以解决占有且等待的问题，但如果并发冲突高，等待时间过长时，会严重影响CPU效率；Java中synchronized配合wait，notify，notifyAll方法能实现等待-通知机制，解决这一问题；

 当一个线程进入临界区后，由于某些条件不满足，需要进入等待状态，调用wait方法，线程会被阻塞，并添加到锁的等待队列中，，同时线程会释放持有的锁，使得其他线程有机会获取该锁，进入临界区；当线程再次满足某些条件是，通过调用notify或notifyAll方法，通知等待队列中的线程，告诉它条件**曾经满足过**，可以尝试获得锁（可能再次失败）；

# 并发带来的问题
- 安全性问题
  - 多个线程同时访问同一个数据，会出现并发问题，这叫做数据竞争；
  - 多个线程的执行顺序会导致不同的结果，即结果依赖线程执行顺序，这叫做竞态条件；
  
 数据竞争和竞态条件问题通过互斥解决，即通过锁；
- 活跃性问题
   前面提到了共享数据竞争导致的死锁问题，其实还可能导致其他问题：
  - 活锁，线程之间同时释放共享数据，企图让对方获取所有资源，导致无法运行；
  - 饥饿，线程一直无法获取所需的共享资源，而无法执行；
  
  活锁问题，可以通过某种规则，控制释放时机，使得对方能获取所有的资源；饥饿问题，可以通过公平锁，保证所有线程都能公平有序的获取共享资源；	
- 性能问题
  为了解决并发问题，使用了锁，但反过来，使用锁会影响并发的效率；解决锁带来的性能问题，或者说更好的提高锁的性能：
   - 使用无锁算法和数据结构；比如TLS，Atomic，乐观锁，copy-on-write
   - 减少锁持有时间；使用细粒度的锁，比如读写锁，分段锁
   
  性能的度量从三个方面

# 管程

# 线程&线程的生命周期
# 线程池&Future

# 读写锁

# 乐观锁&悲观锁

# ReadWriteLock
# StampedLock

# Semaphore
# Lock&Condition

# CountDownLatch&CyclicBarrier

# Java并发容器
# 原子